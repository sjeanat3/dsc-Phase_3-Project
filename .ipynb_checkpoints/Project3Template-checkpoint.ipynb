{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skye and Drew's Excellent Adventure\n",
    "## Predictive Maintenance of Hydraulic Pumps with Industrial Applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hydraulic Machine](./images/NTT-Sept-17.png)\n",
    "## Overview\n",
    "\n",
    "A one-paragraph overview of the project, including the business problem, data, methods, results and recommendations.\n",
    "\n",
    "An Hydroponic Start-up is looking to future proof their irrigation systems by monitoring the operation of mechanical components through various sensor data. They would like recommendations for which sensors provide the best predictive data for understanding the maintenance condition of their hydraulic pumps. We used our sensor data from 17 separate sensors collected over 2205 60 hydraulic pump cycles. The pump condition was recorded for each cycle. First, we performed feature extraction to condense the time-series data into a usable set of features and then used statistical analysis tools XGBoost and K-Nearest Neighbors to train our predictive models.\n",
    "\n",
    "## Business Problem\n",
    "\n",
    "Summary of the business problem you are trying to solve, and the data questions that you plan to answer to solve them.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- Who are your stakeholders?\n",
    "- What are your stakeholders' pain points related to this project?\n",
    "- Why are your predictions important from a business perspective?\n",
    "- Does your business understanding/stakeholder require a specific type of model?\n",
    "    - For example: a highly regulated industry would require a very transparent/simple/interpretable model, whereas a situation where the model itself is your deliverable would likely benefit from a more complex and thus stronger model\n",
    "   \n",
    "\n",
    "Additional questions to consider for classification:\n",
    "\n",
    "- What does a false positive look like in this context?\n",
    "- What does a false negative look like in this context?\n",
    "- Which is worse for your stakeholder?\n",
    "- What metric are you focusing on optimizing, given the answers to the above questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "Describe the data being used for this project.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- Where did the data come from, and how do they relate to the data analysis questions?\n",
    "- What do the data represent? Who is in the sample and what variables are included?\n",
    "- What is the target variable?\n",
    "- What are the properties of the variables you intend to use?\n",
    "\n",
    "<p>\n",
    "<a href=\"https://archive.ics.uci.edu/ml/datasets/Condition+monitoring+of+hydraulic+systems#\">**This data**</a> comes from a set of sensor measurements taken during 2205 sixty second cycles of a hydraulic pump testing rig. During the testing the pump's maintenance status was recorded. These various metrics of the test rigs physical condition will be the target variable for our tests. The sensor data will be the predictors.\n",
    "\n",
    "The goal will be to use sensor data (such as temperature, tank pressure, vibration magnitude, etc.) to\n",
    "predict the state of the hydraulic pump.\n",
    "\n",
    "The data is split between sensors. Each sensor has a specific sample rate qhich cooresponds to the columns\n",
    "in its table. So `TS1.txt` contains temprature readings from one sensor. Its sample rate was 1hz for\n",
    "each 60 second pump cycle. Therefore, in the `TS1.txt` file there are 60 columns and 2205 rows of data.\n",
    " \n",
    "## Structure of the Data\n",
    "**Okay, so the structure of the data is this:**\n",
    "1. The rows represent 1 cycle of the hydraulic test rig.\n",
    "2. The individual txt files are sensor readings, rows represent a cycle, each column is a reading\n",
    "   from that specific sensor.\n",
    "3. Readings from each table are given in hz, and each cycle lasted 60 seconds. So, a 1hz sensor\n",
    "   provides a 60 column by 2205 row table.\n",
    "4. \"Profile.txt\" contains a 5 column by 2205 row table with system states encoded in each column.\n",
    "\n",
    "# Target Variables\n",
    "**Now that we can see the structure** of our target variables a little more clearly lets take a\n",
    "look at the `profile.txt` file in our dataset. \n",
    "\n",
    "I will pull it inot a primary DataFrame object, so that we can continue to work with it; adding \n",
    "predictor variables and iterating over a test pipeline to find the best combinations for prediction.\n",
    "\n",
    "Setting this up just requires pulling in the five columns and assigning column names based on our\n",
    "encoding keys from the above dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.errors import ParserError\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Describe and justify the process for preparing the data for analysis.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- Were there variables you dropped or created?\n",
    "- How did you address missing values or outliers?\n",
    "- Why are these choices appropriate given the data and the business problem?\n",
    "- Can you pipeline your preparation steps to use them consistently in the modeling process?\n",
    "\n",
    "Each row represents one full cycle and each column represents one sample (in this case 1 second) of readings from the temperatue sensor. To create features from this data we will need to come up with methods for aggregating each row of the sensor data into a single column of data.\n",
    "\n",
    "##### Raw Table (ex: TS1.txt)\n",
    "| cycle    |1s |2s |3s |.. |60s|\n",
    "| :---:    |---|---|---|---|---|\n",
    "| first:| 0 | 1 | 2 |...|59 |\n",
    "| second:| 0 | 1 | 2 |...|59 |\n",
    "|   ...    |...|...|...|...|...|\n",
    "| last: | 0 | 1 | 2 |...|59 |\n",
    "\n",
    "\n",
    "##### Taking the average of each row:\n",
    "| cycle    |1s-60s | << |\n",
    "| :---:    | :---: |:---|\n",
    "| first:| avg[0]| << |\n",
    "| second:| avg[1]| << |\n",
    "|   ...    |  ...  | << |\n",
    "| last: |avg[-1]| << |\n",
    " \n",
    "* If we apply this \"pattern\" to `TS1.txt` we end up with one feature column: *the mean temperature reading\n",
    "from the sensor for all cycles*. \n",
    "* Repeating this pattern for each table of **sensor data** creates a full feature set of mean readings for\n",
    "all 17 sensors across each **2205 pump cycles**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "tables = {}\n",
    "for itm in glob.iglob(\"./**/*.txt\"):\n",
    "    id = os.path.basename(itm)\n",
    "    id = id[:-4]\n",
    "    if id in [\"documentation\", \"description\", \"profile\"]:\n",
    "        continue\n",
    "    print(id)\n",
    "    try:\n",
    "        tables.update({id: pd.read_csv(itm, header=None,  sep='\\t')})\n",
    "    except ParserError as err:\n",
    "        print(err)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "Describe and justify the process for analyzing or modeling the data.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- How will you analyze the data to arrive at an initial approach?\n",
    "- How will you iterate on your initial approach to make it better?\n",
    "- What model type is most appropriate, given the data and the business problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "The evaluation of each model should accompany the creation of each model, and you should be sure to evaluate your models consistently.\n",
    "\n",
    "Evaluate how well your work solves the stated business problem. \n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- How do you interpret the results?\n",
    "- How well does your model fit your data? How much better is this than your baseline model? Is it over or under fit?\n",
    "- How well does your model/data fit any relevant modeling assumptions?\n",
    "\n",
    "For the final model, you might also consider:\n",
    "\n",
    "- How confident are you that your results would generalize beyond the data you have?\n",
    "- How confident are you that this model would benefit the business if put into use?\n",
    "- What does this final model tell you about the relationship between your inputs and outputs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Understanding\n",
    "\n",
    "- What does a baseline, model-less prediction look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to arrive at a baseline prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First $&(@# Model\n",
    "\n",
    "Before going too far down the data preparation rabbit hole, be sure to check your work against a first 'substandard' model! What is the easiest way for you to find out how hard your problem is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here for your first 'substandard' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to evaluate your first 'substandard' model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Iterations\n",
    "\n",
    "Now you can start to use the results of your first model to iterate - there are many options!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to iteratively improve your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to evaluate your iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Final' Model\n",
    "\n",
    "In the end, you'll arrive at a 'final' model - aka the one you'll use to make your recommendations/conclusions. This likely blends any group work. It might not be the one with the highest scores, but instead might be considered 'final' or 'best' for other reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to show your final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here to evaluate your final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Provide your conclusions about the work you've done, including any limitations or next steps.\n",
    "\n",
    "Questions to consider:\n",
    "\n",
    "- What would you recommend the business do as a result of this work?\n",
    "- How could the stakeholder use your model effectively?\n",
    "- What are some reasons why your analysis might not fully solve the business problem?\n",
    "- What else could you do in the future to improve this project (future work)?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
